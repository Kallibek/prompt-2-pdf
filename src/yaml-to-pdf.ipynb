{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772fe8d7",
   "metadata": {},
   "source": [
    "# Imports and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa54aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from markdown_pdf import MarkdownPdf, Section\n",
    "\n",
    "# Load environment variables (e.g. OPENAI_API_KEY)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb159f",
   "metadata": {},
   "source": [
    "# User‐configurable variables (formerly CLI args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0259349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file   = r\"..\\results\\Snowflake_comm_skills_dialogs.pdf\"\n",
    "model         = \"gpt-4.1-mini\"         # --model\n",
    "toc_level     = 3                      # --toc-level\n",
    "optimize      = False                  # --optimize\n",
    "use_web_search= False                   # --no-web-search → False\n",
    "max_output_tokens = 2000\n",
    "prompts_filename = r\"..\\prompts\\Snowflake_comm_skills_dialogs.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c450e6c",
   "metadata": {},
   "source": [
    "# Helper function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c18dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown_from_prompt(user_prompt, client):\n",
    "    try:\n",
    "        prompt = [\n",
    "            {\"role\": \"system\", \"content\": (\n",
    "                #\"You are a coach helping me to improve my verbal communication skills. \"\n",
    "                \"Provide output in Markdown. \"\n",
    "                \"Use **bold** text for headers and not don't use '#' or '#'s headers. \"\n",
    "                \"Don't add line separators in response. \"\n",
    "                # \"Add code snippets where needed.\"\n",
    "            )},\n",
    "            {\"role\": \"user\", \"content\": (\n",
    "                user_prompt + \n",
    "                \"\\n\\n\"\n",
    "                )\n",
    "             },\n",
    "        ]\n",
    "        tools = [{\"type\": \"web_search_preview\"}] if use_web_search else []\n",
    "        response = client.responses.create(\n",
    "            model=model,\n",
    "            tools=tools,\n",
    "            input=prompt,\n",
    "            max_output_tokens = max_output_tokens\n",
    "        )\n",
    "        text = f\"Prompt: {user_prompt}\\n\\n\" + response.output_text.strip()\n",
    "        return f\"\\n---\\n{text}\"\n",
    "    except Exception as e:\n",
    "        print(f\"AI request failed for node '{user_prompt}': {e}\")\n",
    "        return f\"{user_prompt}\\n\\n---\\n\\n\"\n",
    "\n",
    "def process_prompts(prompts_text, client, pdf, css):\n",
    "    # lines = prompts_text.strip().splitlines()\n",
    "    lines = [line for line in prompts_text.splitlines() if line.strip()]\n",
    "    \n",
    "    len_lines = len(lines)\n",
    "    \n",
    "    section_md = \"\"\n",
    "    for idx, line in enumerate(lines, start=1):\n",
    "        stripped = line.lstrip()\n",
    "        # skip empty lines\n",
    "        if not stripped:\n",
    "            continue\n",
    "        # skip lines starting with '#'\n",
    "        elif stripped.startswith(\"#\"):\n",
    "            section_md = f\"{section_md}\\n\\n{stripped}\"\n",
    "        else:\n",
    "            print(f\"Processing Line {idx}/{len_lines} ({round(idx*100/len_lines)}%)...\")\n",
    "            md = generate_markdown_from_prompt(stripped, client)\n",
    "            #md = \"Test\"\n",
    "            section_md = f\"{section_md}\\n\\n{md}\\n\\n\"\n",
    "            pdf.add_section(Section(section_md), user_css=css)\n",
    "            section_md = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d523a74",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67be39b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Snowflake Communication Skills Dialogs\n",
      "\n",
      "## Sales & Negotiation Skills\n",
      "\n",
      "### Pitching & Closing\n",
      "\n",
      "1. Generate a dialog between A and B, in which A coaches B through a sales‐call scenario with a new prospect, focusing on improving B’s vocal variety and body‐language cues.\n",
      "2. Generate a dialog between A and B, in which A role‐plays a cold call with B to a sales lead, emphasizing energy in B’s voice a\n"
     ]
    }
   ],
   "source": [
    "# Open the file in read mode and assign its contents to chatgpt_prompts\n",
    "with open(prompts_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    chatgpt_prompts = f.read()\n",
    "\n",
    "# Optional: print to verify\n",
    "print(chatgpt_prompts[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4e4be",
   "metadata": {},
   "source": [
    "# Instantiate client, load YAML, and generate Markdown sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f91382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Line 4/66 (6%)...\n",
      "Processing Line 5/66 (8%)...\n",
      "Processing Line 6/66 (9%)...\n",
      "Processing Line 7/66 (11%)...\n",
      "Processing Line 8/66 (12%)...\n",
      "Processing Line 9/66 (14%)...\n",
      "Processing Line 10/66 (15%)...\n",
      "Processing Line 11/66 (17%)...\n",
      "Processing Line 14/66 (21%)...\n",
      "Processing Line 15/66 (23%)...\n",
      "Processing Line 16/66 (24%)...\n",
      "Processing Line 17/66 (26%)...\n",
      "Processing Line 18/66 (27%)...\n",
      "Processing Line 20/66 (30%)...\n",
      "Processing Line 21/66 (32%)...\n",
      "Processing Line 22/66 (33%)...\n",
      "Processing Line 23/66 (35%)...\n",
      "Processing Line 26/66 (39%)...\n",
      "Processing Line 27/66 (41%)...\n",
      "Processing Line 28/66 (42%)...\n",
      "Processing Line 29/66 (44%)...\n",
      "Processing Line 30/66 (45%)...\n",
      "Processing Line 33/66 (50%)...\n",
      "Processing Line 34/66 (52%)...\n",
      "Processing Line 35/66 (53%)...\n",
      "Processing Line 36/66 (55%)...\n",
      "Processing Line 38/66 (58%)...\n",
      "Processing Line 39/66 (59%)...\n",
      "Processing Line 42/66 (64%)...\n",
      "Processing Line 43/66 (65%)...\n",
      "Processing Line 44/66 (67%)...\n",
      "Processing Line 45/66 (68%)...\n",
      "Processing Line 46/66 (70%)...\n",
      "Processing Line 48/66 (73%)...\n",
      "Processing Line 49/66 (74%)...\n",
      "Processing Line 50/66 (76%)...\n",
      "Processing Line 51/66 (77%)...\n",
      "Processing Line 53/66 (80%)...\n",
      "Processing Line 54/66 (82%)...\n",
      "Processing Line 55/66 (83%)...\n",
      "Processing Line 56/66 (85%)...\n",
      "Processing Line 57/66 (86%)...\n",
      "Processing Line 58/66 (88%)...\n",
      "Processing Line 59/66 (89%)...\n",
      "Processing Line 60/66 (91%)...\n",
      "Processing Line 62/66 (94%)...\n",
      "Processing Line 63/66 (95%)...\n",
      "Processing Line 64/66 (97%)...\n",
      "Processing Line 65/66 (98%)...\n",
      "Processing Line 66/66 (100%)...\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "css = Path(\"custom.css\").read_text(encoding=\"utf-8\")\n",
    "pdf = MarkdownPdf(toc_level=toc_level, optimize=optimize)\n",
    "\n",
    "if not api_key:\n",
    "    print(\"Environment variable OPENAI_API_KEY is not set.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "            \n",
    "process_prompts(chatgpt_prompts, client, pdf, css)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76faa09",
   "metadata": {},
   "source": [
    "# Save as PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67d90a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF successfully saved to ..\\results\\Snowflake_comm_skills_dialogs.pdf\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pdf.save(output_file)\n",
    "    print(f\"PDF successfully saved to {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to save PDF: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd919b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
